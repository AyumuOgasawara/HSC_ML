{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e79230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python : 3.6.13\n",
    "# Numpy: 1.17.0\n",
    "# pandas: 0.25.0\n",
    "# matplotlib: 3.1.1\n",
    "# scipy: 1.3.1\n",
    "# scikit-learn: 0.20.0\n",
    "\n",
    "import os, sys, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "#mpl.use('TKAgg',warn=False, force=True) #set MPL backend.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.transforms as transforms\n",
    "import pickle #save/load python data objects (dictionaries/arrays)\n",
    "import multiprocessing\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import datetime\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.colorbar import colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe279f",
   "metadata": {},
   "source": [
    "## 使用する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルのLoading/saving\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "# デバック用\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "# ファイル実行用\n",
    "    # with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "#------------------------------------------------------------------------------------------------------------ \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------ \n",
    "\n",
    "# プロットするための関数\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------ \n",
    "\n",
    "\n",
    "def make_cmap(colors, position=None, bit =False): \n",
    "    #bit=Flaseはcolors = [(1,1,1), (101/255,236/255,101/255)] \n",
    "    #bit=Trueはcolors = [(255,255,255), (101,236,101)] →if bit: で形を変形\n",
    "    bit_rgb = np.linspace(0,1,256) #0~1を256分割\n",
    "    if position == None:\n",
    "        position =np.linspace(0,1,len(colors))\n",
    "    else:\n",
    "        if len(position) != len(colors):\n",
    "            sys.exit(\"position length must be the same as colors\")\n",
    "        elif position[0] != 0 or position[-1] != 1:\n",
    "            sys.exit(\"position must start with 0 and end with 1\")\n",
    "            \n",
    "    if bit: #ここでcolorsをbit=Trueの場合と同じ形にする\n",
    "        for i in range(len(colors)):\n",
    "            colors[i] = (bit_rgb[colors[i][0]],\n",
    "                         bit_rgb[colors[i][1]],\n",
    "                         bit_rgb[colors[i][2]])\n",
    "            \n",
    "    cdict = {'red':[], 'green':[], 'blue':[]}\n",
    "    for pos, color in zip(position, colors):\n",
    "        cdict['red'].append((pos, color[0], color[0]))\n",
    "        cdict['green'].append((pos, color[1], color[1]))\n",
    "        cdict['blue'].append((pos, color[2], color[2]))\n",
    "    cmap = mpl.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "    return cmap\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Customised histogram function to help plotting on log scale and other aspects (courtesy of Justin Bray)\n",
    "def histvals(a, logmin=0.0, cumulative=False, **kwargs):  # **kwargsは辞書型で変数を入れることができる\n",
    "  \"\"\"Return x/y values for plotting a histogram.\"\"\"\n",
    "\n",
    "  if cumulative: # 累積に関して使うときにもう一度詳しくみた方がいい\n",
    "    lims = kwargs.pop('bins', [a.min(), a.max()]) # ビンのサイズの最大値と最小値\n",
    "    density = kwargs.pop('density', False) \n",
    "    assert not kwargs, 'Unprocessed kwargs in histvals.' # kwargsに使用されてない引数がある場合アラートする\n",
    "\n",
    "    # Reduce length of array, if possible, by combining duplicate values.\n",
    "    bins,counts = np.unique(a, return_counts=True)\n",
    "    #counts, bins = np.histogram(a, **kwargs)\n",
    "\n",
    "    bins = np.concatenate(( [lims[0]], bins, [lims[-1]] ))\n",
    "    counts = np.concatenate(( [0], np.cumsum(counts) )) # np.cumsum(counts)で累積している\n",
    "\n",
    "    if density:\n",
    "      counts = counts*1./counts.max()\n",
    "  else:\n",
    "    counts, bins = np.histogram(a, **kwargs) #countには各ビンの度数 binsにはビンの境界値が入る\n",
    "\n",
    "  x = np.concatenate( list(zip( bins[:-1], bins[1:] )) ) #軸が対数であるため、わかりやすく表示するため、x,yはどちらも値を2つずつ持ってる\n",
    "  y = np.concatenate( list(zip( counts,    counts   )) )\n",
    "\n",
    "  if not cumulative:\n",
    "    x = np.concatenate(( [x[0]], x, [x[-1]] ))\n",
    "    y = np.concatenate(( [0],    y,  [0]    ))\n",
    "\n",
    "  # 負のあたいがあったとしてもうまくプロットされるようにloglim(非常に小さい正の値)にしてる\n",
    "  if logmin:\n",
    "    y = (y > 0)*y + (y <= 0)*logmin\n",
    "  return x,y\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------ \n",
    "\n",
    "# 解析するための関数\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_basic_hists(df, df_spec, place):\n",
    "    bins = np.linspace(14, 26,150) #10~26の範囲を100分割し、それをビンのサイズとする\n",
    "    linewidth = 1 #線の太さ\n",
    "    plt.subplots(1, 1, figsize=(6,3.5)) #図の個数指定&サイズ指定\n",
    "\n",
    "    xvar='i_psfflux_mag' # 指定するカラム\n",
    "    \n",
    "    x, s = histvals(df[df['class_pred']=='STAR'][xvar].values, bins=bins) #xにはビンのの値が２つずつ入ってる sにはヒストグラムの値が格納\n",
    "    x, g = histvals(df[df['class_pred']=='GALAXY'][xvar].values, bins=bins)\n",
    "    x, q = histvals(df[df['class_pred']=='QSO'][xvar].values, bins=bins)\n",
    "\n",
    "    plt.plot(x, s, label='Stars: {0:.0f}'.format(np.sum(s)/2), color=star_c, linewidth=linewidth)\n",
    "    plt.plot(x, g, label='Galaxies: {0:.0f}'.format(np.sum(g)/2), color=galaxy_c, linewidth=linewidth)\n",
    "    plt.plot(x, q, label='Quasars: {0:.0f}'.format(np.sum(q)/2), color=quasar_c, linewidth=linewidth)\n",
    "    plt.plot(x, g+q+s, label='All sources', color='black', linewidth=0.2, ls='--')\n",
    "\n",
    "    x, s = histvals(df_spec[df_spec['class']=='STAR'][xvar].values, bins=bins) #xにはビンのの値が２つずつ入ってる sにはヒストグラムの値が格納\n",
    "    x, g = histvals(df_spec[df_spec['class']=='GALAXY'][xvar].values, bins=bins)\n",
    "    x, q = histvals(df_spec[df_spec['class']=='QSO'][xvar].values, bins=bins)\n",
    "\n",
    "    plt.plot(x, s, label='Spec stars: {0:.0f}'.format(np.sum(s)/2), color=star_c, ls='--',linewidth=linewidth)\n",
    "    plt.plot(x, g, label='Spec galaxies: {0:.0f}'.format(np.sum(g)/2), color=galaxy_c, ls='--',linewidth=linewidth)\n",
    "    plt.plot(x, q, label='Spec quasars: {0:.0f}'.format(np.sum(q)/2), color=quasar_c, ls='--',linewidth=linewidth)\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('psf i magnitude', fontsize = 13)\n",
    "    plt.ylabel('Number of sources', fontsize = 13)\n",
    "    plt.minorticks_on()\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "    if mag_lim:\n",
    "        plt.savefig('HSC_classifynew/' + place + '/mag_lim/New-sources-spec-hist-imag.pdf')\n",
    "    else:\n",
    "        plt.savefig('HSC_classifynew/' + place + '/no_mag_lim/New-sources-spec-hist-imag.pdf')\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def plot_new_feature_hist(df_spec, df_g, df_q, df_s, place):\n",
    "    print('Making feature histogram plot... features-.pdf')\n",
    "    \n",
    "    figsize = (10,3.5)\n",
    "    linewidth = 1.2\n",
    "    linewidth_s = 0.8\n",
    "    elinewidth = 0.5\n",
    "    capthick = 0.5\n",
    "    spec_capsize = 1\n",
    "    photo_capsize = 4\n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, gridspec_kw=dict(width_ratios=[1,1.3,1]), figsize=figsize)\n",
    "\n",
    "    plt.sca(ax1) \n",
    "    # 特徴\n",
    "    xlabels = ['g','r','i','z','y']\n",
    "    plot_columns = ['g_psfflux_mag','r_psfflux_mag', 'i_psfflux_mag', 'z_psfflux_mag', 'y_psfflux_mag']\n",
    "\n",
    "    # offsetを使うことでプロット同士が被らないようにしている。transでは軸をデータと同じ形式にしている\n",
    "    offset = lambda p: transforms.ScaledTranslation(p/72.,0, plt.gcf().dpi_scale_trans)\n",
    "    trans = plt.gca().transData\n",
    "\n",
    "    \n",
    "    # Photometric sources\n",
    "    plt.errorbar(plot_columns, df_g[plot_columns].mean(), yerr=df_g[plot_columns].std(), color=galaxy_c, ls=ls, capsize=photo_capsize, capthick=capthick, linewidth=linewidth, elinewidth=elinewidth, label='Galaxies: {0}'.format(len(df_g)), transform=trans+offset(-5))\n",
    "    plt.errorbar(plot_columns, df_q[plot_columns].mean(), yerr=df_q[plot_columns].std(), color=quasar_c, ls=ls, capsize=photo_capsize, capthick=capthick, linewidth=linewidth, elinewidth=elinewidth, label='Quasars: {0}'.format(len(df_q)), transform=trans+offset(-1))\n",
    "    plt.errorbar(plot_columns, df_s[plot_columns].mean(), yerr=df_s[plot_columns].std(), color=star_c, ls=ls, capsize=photo_capsize, capthick=capthick, linewidth=linewidth, elinewidth=elinewidth, label='Stars: {0}'.format(len(df_s)), transform=trans+offset(+3))\n",
    "\n",
    "    # Spectroscopic sources\n",
    "    a = plt.errorbar(plot_columns, df_spec[df_spec['class']=='GALAXY'][plot_columns].mean(), yerr=df_spec[df_spec['class']=='GALAXY'][plot_columns].std(), color=galaxy_c, ls='--', capsize=spec_capsize, capthick=capthick, linewidth=linewidth_s, elinewidth=elinewidth, label='Spec galaxies: {0}'.format(len(df_spec[df_spec['class']=='GALAXY'])), transform=trans+offset(-3))\n",
    "    a[-1][0].set_linestyle('--')\n",
    "    b = plt.errorbar(plot_columns, df_spec[df_spec['class']=='QSO'][plot_columns].mean(), yerr=df_spec[df_spec['class']=='QSO'][plot_columns].std(), color=quasar_c, ls='--', capsize=spec_capsize, capthick=capthick, linewidth=linewidth_s, elinewidth=elinewidth, label='Spec quasars: {0}'.format(len(df_spec[df_spec['class']=='QSO'])), transform=trans+offset(+1))\n",
    "    b[-1][0].set_linestyle('--')\n",
    "    c = plt.errorbar(plot_columns, df_spec[df_spec['class']=='STAR'][plot_columns].mean(), yerr=df_spec[df_spec['class']=='STAR'][plot_columns].std(), color=star_c, ls='--', capsize=spec_capsize, capthick=capthick, linewidth=linewidth_s, elinewidth=elinewidth, label='Spec stars: {0}'.format(len(df_spec[df_spec['class']=='STAR'])), transform=trans+offset(+5))\n",
    "    c[-1][0].set_linestyle('--')\n",
    "\n",
    "#     plt.legend(frameon=False)\n",
    "    plt.gca().yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "    plt.xticks(np.arange(len(xlabels)), xlabels, rotation=rotation, fontsize=11) # 補助メモリのカスタマイズ\n",
    "    plt.xlim(-0.4, len(xlabels)-0.6) # auto scale with sticky_edges=False doesn't seem to work, so do manually:\n",
    "#     plt.xlabel('Feature name', fontsize=13)\n",
    "    plt.ylabel('Magnitude', fontsize=13)\n",
    "    plt.yticks(np.arange(16, 25, step=2), fontsize = 10)\n",
    "    plt.ylim(25,16)\n",
    "    #ax1.margins(x=0.4)\n",
    "    #ax1.use_sticky_edges = False\n",
    "    #ax1.autoscale_view(scalex=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ishape\n",
    "    plt.sca(ax2)\n",
    "    x, y = histvals(df_g.ishape.values, bins=bins_i)\n",
    "    plt.plot(x, y, ls=ls, color=galaxy_c)\n",
    "    x, y = histvals(df_q.ishape.values, bins=bins_i)\n",
    "    plt.plot(x, y, ls=ls, color=quasar_c)\n",
    "    x, y = histvals(df_s.ishape.values, bins=bins_i)\n",
    "    plt.plot(x, y, ls=ls, color=star_c)\n",
    "    \n",
    "    x, y = histvals(df_spec[df_spec['class']=='GALAXY'].ishape.values, bins=bins_i)\n",
    "    plt.plot(x, y, ls='--', color=galaxy_c, linewidth=0.5)\n",
    "    x, y = histvals(df_spec[df_spec['class']=='QSO'].ishape.values, bins=bins_i)\n",
    "    plt.plot(x, y, ls='--', color=quasar_c, linewidth=0.5)\n",
    "    x, y = histvals(df_spec[df_spec['class']=='STAR'].ishape.values, bins=bins_i)\n",
    "    plt.plot(x, y, ls='--', color=star_c, linewidth=0.5)\n",
    "    \n",
    "    #plt.legend(frameon=False)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "#     plt.xlabel('ishape' , fontsize=13)\n",
    "    plt.ylabel('Number' , fontsize=13)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    plt.sca(ax3) \n",
    "\n",
    "    xlabels = ['g-r','r-i','i-z','z-y']\n",
    "    plot_columns = ['g-r','r-i','i-z','z-y']\n",
    "\n",
    "    # offsetを使うことでプロット同士が被らないようにしている。transでは軸をデータと同じ形式にしている\n",
    "    offset = lambda p: transforms.ScaledTranslation(p/72.,0, plt.gcf().dpi_scale_trans)\n",
    "    trans = plt.gca().transData\n",
    "\n",
    "    # Photometric sources\n",
    "    plt.errorbar(plot_columns, df_g[plot_columns].mean(), yerr=df_g[plot_columns].std(), color=galaxy_c, ls=ls, capsize=photo_capsize, capthick=capthick, linewidth=linewidth, elinewidth=elinewidth, label='Predicted galaxies: {0}'.format(len(df_g)), transform=trans+offset(-5))\n",
    "    plt.errorbar(plot_columns, df_q[plot_columns].mean(), yerr=df_q[plot_columns].std(), color=quasar_c, ls=ls, capsize=photo_capsize, capthick=capthick, linewidth=linewidth, elinewidth=elinewidth, label='Predicted quasars: {0}'.format(len(df_q)), transform=trans+offset(-1))\n",
    "    plt.errorbar(plot_columns, df_s[plot_columns].mean(), yerr=df_s[plot_columns].std(), color=star_c, ls=ls, capsize=photo_capsize, capthick=capthick, linewidth=linewidth, elinewidth=elinewidth, label='Predicted stars: {0}'.format(len(df_s)), transform=trans+offset(+3))\n",
    "\n",
    "    # Spectroscopic sources\n",
    "    a = plt.errorbar(plot_columns, df_spec[df_spec['class']=='GALAXY'][plot_columns].mean(), yerr=df_spec[df_spec['class']=='GALAXY'][plot_columns].std(), color=galaxy_c, ls='--', capsize=spec_capsize, capthick=capthick, linewidth=linewidth_s, elinewidth=elinewidth, label='Galaxies with spectra: {0}'.format(len(df_spec[df_spec['class']=='GALAXY'])), transform=trans+offset(-3))\n",
    "    a[-1][0].set_linestyle('--')\n",
    "    b = plt.errorbar(plot_columns, df_spec[df_spec['class']=='QSO'][plot_columns].mean(), yerr=df_spec[df_spec['class']=='QSO'][plot_columns].std(), color=quasar_c, ls='--', capsize=spec_capsize, capthick=capthick, linewidth=linewidth_s, elinewidth=elinewidth, label='Quasars with spectra: {0}'.format(len(df_spec[df_spec['class']=='QSO'])), transform=trans+offset(+1))\n",
    "    b[-1][0].set_linestyle('--')\n",
    "    c = plt.errorbar(plot_columns, df_spec[df_spec['class']=='STAR'][plot_columns].mean(), yerr=df_spec[df_spec['class']=='STAR'][plot_columns].std(), color=star_c, ls='--', capsize=spec_capsize, capthick=capthick, linewidth=linewidth_s, elinewidth=elinewidth, label='Stars with spectra: {0}'.format(len(df_spec[df_spec['class']=='STAR'])), transform=trans+offset(+5))\n",
    "    c[-1][0].set_linestyle('--')\n",
    "    \n",
    "    \n",
    "    plt.gca().yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "    plt.xticks(np.arange(len(xlabels)), xlabels, rotation=rotation, fontsize=11) # 補助メモリのカスタマイズ\n",
    "    plt.xlim(-0.4, len(xlabels)-0.6) # auto scale with sticky_edges=False doesn't seem to work, so do manually:\n",
    "#     plt.xlabel('Feature name' , fontsize=13)\n",
    "    plt.ylabel('Magnitude Diﬀerence' , fontsize=13)\n",
    "    plt.yticks(fontsize=10)\n",
    "    #ax1.margins(x=0.4)\n",
    "    #ax1.use_sticky_edges = False\n",
    "    #ax1.autoscale_view(scalex=True)\n",
    "    plt.xticks(fontsize = 10)\n",
    "    plt.yticks(fontsize = 10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax1.tick_params(which='both', right=True)\n",
    "    ax2.tick_params(which='both', right=True)\n",
    "    ax3.tick_params(which='both', right=True)\n",
    "\n",
    "    if mag_lim:\n",
    "        f.savefig('HSC_classifynew/' + place + '/mag_lim/New-sources-features-perclass.pdf')\n",
    "    else:\n",
    "        f.savefig('HSC_classifynew/' + place + '/no_mag_lim/New-sources-features-perclass.pdf')\n",
    "\n",
    "    '''\n",
    "    # psf_i - cmod_i　のヒストグラム. Resolved sourceかどうか?\n",
    "    # dfから探す。これはresolvedを特徴量にしないときのことを考えて.\n",
    "    plt.sca(ax2)\n",
    "    x1, y1 = histvals(df.loc[missed_star_as_quasar.index.values].resolved_i.values, bins=bins_res, density=density)\n",
    "    plt.plot(x1, y1, label='missed stars as quasars', ls=missed_ls, color=star_c)\n",
    "    x2, y2 = histvals(df.loc[missed_quasar_as_star.index.values].resolved_i.values, bins=bins_res, density=density)\n",
    "    plt.plot(x2, y2, label='missed quasars as stars', ls=missed_ls, color=quasar_c)\n",
    "    x3, y3 = histvals(df.loc[correct_star.index.values].resolved_i.values, bins=bins_res, density=density)\n",
    "    plt.plot(x3, y3, label='correct stars', ls=correct_ls, color=star_c)\n",
    "    x4, y4 = histvals(df.loc[correct_quasar.index.values].resolved_i.values, bins=bins_res, density=density)\n",
    "    plt.plot(x4, y4, label='correct quasars', ls=correct_ls, color=quasar_c)\n",
    "    #plt.legend(frameon=False)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('| PSF i - cmodel i | [magnitude]')\n",
    "    plt.ylabel('Number')\n",
    "    plt.tight_layout()\n",
    "    f.savefig('HSC_analysis_save/psf/features-star-quasar'+plot_data_label+'.pdf')\n",
    "    '''\n",
    "    '''\n",
    "    # Histogram of errors, high error sources classified worse?\n",
    "    # Searching the original df because we don't use errors as a feature (they don't improve classification results)\n",
    "    plt.sca(ax2)\n",
    "    x1, y1 = histvals(df.loc[missed_star_as_quasar.index.values].psferr_r.values, bins=bins_err, density=density)\n",
    "    plt.plot(x1, y1, label='missed stars as quasars', ls=missed_ls, color=star_c)\n",
    "    x2, y2 = histvals(df.loc[missed_quasar_as_star.index.values].psferr_r.values, bins=bins_err, density=density)\n",
    "    plt.plot(x2, y2, label='missed quasars as stars', ls=missed_ls, color=quasar_c)\n",
    "    x3, y3 = histvals(df.loc[correct_star.index.values].psferr_r.values, bins=bins_err, density=density)\n",
    "    plt.plot(x3, y3, label='correct stars', ls=correct_ls, color=star_c)\n",
    "    x4, y4 = histvals(df.loc[correct_quasar.index.values].psferr_r.values, bins=bins_err, density=density)\n",
    "    plt.plot(x4, y4, label='correct quasars', ls=correct_ls, color=quasar_c)\n",
    "    #plt.legend(frameon=False)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(top=2*10**5)\n",
    "    plt.xlabel('PSF r error [magnitude]')\n",
    "    plt.ylabel('Number')\n",
    "    plt.tight_layout()\n",
    "    f.savefig('star-quasar-'+plot_data_label+'.pdf')\n",
    "    '''\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_new_prob_hist(df, df_g, df_q, df_s,  place):\n",
    "    print('Plotting probability histograms...')\n",
    "    bins_p = np.linspace(0,1,200)\n",
    "\n",
    "    # ------ new plot ------\n",
    "\n",
    "    # Plot histogram over probabilities\n",
    "    f, axs = plt.subplots(1, 2, figsize=(10,3.5), sharey=False, sharex=False) # two plots side by side\n",
    "    plt.sca(axs[0])\n",
    "    xpg, yg_prob = histvals(df_g.prob_g, bins=bins_p, cumulative=False, density=False)\n",
    "    xpq, yq_prob = histvals(df_q.prob_q, bins=bins_p, cumulative=False, density=False)\n",
    "    xps, ys_prob = histvals(df_s.prob_s, bins=bins_p, cumulative=False, density=False)\n",
    "    plt.plot(xpg, yg_prob, label='Galaxies', color=galaxy_c, linewidth=linewidth)\n",
    "    plt.plot(xpq, yq_prob, label='Quasars', color=quasar_c, linewidth=linewidth)\n",
    "    plt.plot(xps, ys_prob, label='Stars', color=star_c, linewidth=linewidth)\n",
    "    #plt.plot(xpg, yg_prob+yq_prob+ys_prob, label='All', color='black', linewidth=0.2, ls='--') # sum of all\n",
    "\n",
    "    # get correct objects from spec df to overlay on plot\n",
    "    correct_galaxy = df[ (df['class'] == df['class_pred']) & (df['class'] == 'GALAXY') ]\n",
    "    correct_quasar = df[ (df['class'] == df['class_pred']) & (df['class'] == 'QSO') ]\n",
    "    correct_star = df[ (df['class'] == df['class_pred']) & (df['class'] == 'STAR') ]\n",
    "    # Plot spectrosopically observed correct sources\n",
    "    x1, y1 = histvals(df.loc[correct_galaxy.index].prob_g, bins=bins_p, cumulative=False, density=False)\n",
    "    plt.plot(x1, y1, label='Correct tset galaxies', ls='--', linewidth=0.5, color=galaxy_c)\n",
    "    x1, y1 = histvals(df.loc[correct_quasar.index].prob_q, bins=bins_p, cumulative=False, density=False)\n",
    "    plt.plot(x1, y1, label='Correct test quasars', ls='--', linewidth=0.5, color=quasar_c)\n",
    "    x1, y1 = histvals(df.loc[correct_star.index].prob_s, bins=bins_p, cumulative=False, density=False)\n",
    "    plt.plot(x1, y1, label='Correct test stars', ls='--', linewidth=0.5, color=star_c)\n",
    "    plt.xlabel('RF classification probability', fontsize=13)\n",
    "    plt.ylabel('Number of sources', fontsize=13)\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(fontsize = 10)\n",
    "    plt.yticks(fontsize = 10)\n",
    "#     plt.legend(frameon=False)\n",
    "    plt.minorticks_on()\n",
    "    axs[0].tick_params(which='both', right=True)\n",
    "\n",
    "    # plot cumulative normalised histogram over probabilities\n",
    "    plt.sca(axs[1])\n",
    "    #print(bins_p)\n",
    "    xpg_cum, yg_prob_cum = histvals(df_g.prob_g, bins=bins_p, cumulative=True, density=True)\n",
    "    xpq_cum, yq_prob_cum = histvals(df_q.prob_q, bins=bins_p, cumulative=True, density=True)\n",
    "    xps_cum, ys_prob_cum = histvals(df_s.prob_s, bins=bins_p, cumulative=True, density=True)\n",
    "    plt.plot(xpg_cum, yg_prob_cum, label='Galaxies', color=galaxy_c, linewidth=linewidth)\n",
    "    plt.plot(xpq_cum, yq_prob_cum, label='Quasars', color=quasar_c, linewidth=linewidth)\n",
    "    plt.plot(xps_cum, ys_prob_cum, label='Stars', color=star_c, linewidth=linewidth)\n",
    "    #print(xpg_cum)\n",
    "    #print( len(bins_p), len(xpg_cum) )\n",
    "    # Plot spectrosopically observed correct sources\n",
    "    x1, y1 = histvals(df.loc[correct_galaxy.index].prob_g, bins=bins_p, cumulative=True, density=True)\n",
    "    plt.plot(x1, y1, label='Correct test galaxies', ls='--', linewidth=0.5, color=galaxy_c)\n",
    "    x1, y1 = histvals(df.loc[correct_quasar.index].prob_q, bins=bins_p, cumulative=True, density=True)\n",
    "    plt.plot(x1, y1, label='Correct test quasars', ls='--', linewidth=0.5, color=quasar_c)\n",
    "    x1, y1 = histvals(df.loc[correct_star.index].prob_s, bins=bins_p, cumulative=True, density=True)\n",
    "    plt.plot(x1, y1, label='Correct test stars', ls='--', linewidth=0.5, color=star_c)\n",
    "    plt.xlabel('RF classification probability', fontsize=13)\n",
    "    plt.ylabel('Fraction of sources per class', fontsize=13)\n",
    "    plt.xticks(fontsize = 10)\n",
    "    plt.yticks(fontsize = 10)\n",
    "    plt.legend(frameon=False, fontsize=\"large\")\n",
    "    plt.minorticks_on()\n",
    "    axs[1].tick_params(which='both', right=True)\n",
    "    plt.tight_layout()\n",
    "    if mag_lim:\n",
    "        f.savefig('HSC_classifynew/' + place + '/mag_lim/New-sources-hist-prob.pdf')\n",
    "    else:\n",
    "        f.savefig('HSC_classifynew/' + place + '/no_mag_lim/New-sources-hist-prob.pdf')\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def load_spec(place):\n",
    "    # Load in spec objects for plotting later\n",
    "    print('Loading df with spec objects...')\n",
    "    df_spec = load_obj('HSC_ML_save/'+place+'/df_spec_classprobs')\n",
    "    # Load in spec df and join class_pred and prob_ columns:\n",
    "    ### NOT DONE ANYMORE, MOVED THIS TO SDSS_ML.PY\n",
    "    ### Everything is in df_spec_classprobs now, rather than df.\n",
    "    '''\n",
    "    data_prep_dict_all = load_obj('data_prep_dict_all')\n",
    "    classes_pred_all = load_obj('classes_pred_all')\n",
    "    classes_pred_all_proba = load_obj('classes_pred_all_proba')\n",
    "    # Get predicted classes from the RF classifier:\n",
    "    df_predclass = pd.DataFrame(classes_pred_all, index=data_prep_dict_all['features_test'].index, columns=['class_pred'])\n",
    "    # Append probabilities to the original df for test data:\n",
    "    df_spec = df_spec.join(df_predclass, how='left')\n",
    "    # Get probabilities from the RF classifier:\n",
    "    df_proba = pd.DataFrame(classes_pred_all_proba, index=data_prep_dict_all['features_test'].index, columns=['prob_g', 'prob_q', 'prob_s'])\n",
    "    # Append probabilities to the original df for test data:\n",
    "    df_spec = df_spec.join(df_proba, how='left')\n",
    "    '''\n",
    "    return df_spec\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def print_result_numbers():\n",
    "    # Count how many have probabilities above 0.9 and 0.99:\n",
    "    print('Newly classified sources: ')\n",
    "    print(df_all['class_pred'].value_counts())\n",
    "    print(' Galaxies with prob greater than 0.9 and 0.99: {0}, {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_all[df_all['prob_g'] > 0.9]), len(df_all[df_all['prob_g'] > 0.99]), len(df_all[df_all['prob_g'] > 0.9])/len(df_g), len(df_all[df_all['prob_g'] > 0.99])/len(df_g) ) )\n",
    "    print(' Quasars with prob greater than 0.9 and 0.99: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_all[df_all['prob_q'] > 0.9]), len(df_all[df_all['prob_q'] > 0.99]), len(df_all[df_all['prob_q'] > 0.9])/len(df_q), len(df_all[df_all['prob_q'] > 0.99])/len(df_q) ) )\n",
    "    print(' Stars with prob greater than 0.9 and 0.99: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_all[df_all['prob_s'] > 0.9]), len(df_all[df_all['prob_s'] > 0.99]), len(df_all[df_all['prob_s'] > 0.9])/len(df_s), len(df_all[df_all['prob_s'] > 0.99])/len(df_s) ) )\n",
    "\n",
    "    # Spec objects\n",
    "    print('\\nSources classified from test dataset: ')\n",
    "    print(df_spec['class_pred'].value_counts())\n",
    "    print(' Galaxies with prob greater than 0.9 and 0.99: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_spec[df_spec['prob_g'] > 0.9]), len(df_spec[df_spec['prob_g'] > 0.99]), len(df_spec[df_spec['prob_g'] > 0.9])/len(df_spec[df_spec['class_pred']=='GALAXY']), len(df_spec[df_spec['prob_g'] > 0.99])/len(df_spec[df_spec['class_pred']=='GALAXY'])  ) )\n",
    "    print(' Quasars with prob greater than 0.9 and 0.99: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_spec[df_spec['prob_q'] > 0.9]), len(df_spec[df_spec['prob_q'] > 0.99]), len(df_spec[df_spec['prob_q'] > 0.9])/len(df_spec[df_spec['class_pred']=='QSO']), len(df_spec[df_spec['prob_q'] > 0.99])/len(df_spec[df_spec['class_pred']=='QSO']) ) )\n",
    "    print(' Stars with prob greater than 0.9 and 0.99: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_spec[df_spec['prob_s'] > 0.9]), len(df_spec[df_spec['prob_s'] > 0.99]), len(df_spec[df_spec['prob_s'] > 0.9])/len(df_spec[df_spec['class_pred']=='STAR']), len(df_spec[df_spec['prob_s'] > 0.99])/len(df_spec[df_spec['class_pred']=='STAR']) ) )\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------ \n",
    "\n",
    "# 未分類天体を分類するための関数\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------ \n",
    "\n",
    "\n",
    "\n",
    "def classify_new_sources(df, feature_columns, source_name, place):\n",
    "    print(' Classifying all rows from {0} at once.'.format(source_name))\n",
    "    rf_pipeline = load_obj('HSC_ML_save/'+place+'/rf_pipeline')\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(' Reading in file: {0} - {1}'.format(source_name, datetime.datetime.utcnow()))\n",
    "    print(' Calculating resolved feature for all rows - {0}'.format(datetime.datetime.utcnow()))\n",
    "    \n",
    "    df['g-r'] = df.g_psfflux_mag - df.r_psfflux_mag\n",
    "    df['r-i'] = df.r_psfflux_mag - df.i_psfflux_mag\n",
    "    df['i-z'] = df.i_psfflux_mag - df.z_psfflux_mag\n",
    "    df['z-y'] = df.z_psfflux_mag - df.y_psfflux_mag\n",
    "    \n",
    "    print(' Predicting classes for all rows - {0}'.format(datetime.datetime.utcnow()))\n",
    "    classes = rf_pipeline.predict(df[feature_columns])\n",
    "    probabilities = rf_pipeline.predict_proba(df[feature_columns])\n",
    "    print(' Turning arrays into DataFrames - {0}'.format(datetime.datetime.utcnow()))\n",
    "    df_classes = pd.DataFrame( classes, columns=['class_pred'] ) # Turn arrays into dfs\n",
    "    df_probabilities = pd.DataFrame( probabilities, columns=['prob_g', 'prob_q', 'prob_s'] )\n",
    "    print(' Appending class/probability dfs to original df - {0}'.format(datetime.datetime.utcnow()))\n",
    "    df = df.join(df_classes, how='left')\n",
    "    df = df.join(df_probabilities, how='left')\n",
    "    print(' Saving new df to disk... {0}'.format(datetime.datetime.utcnow()))\n",
    "#     save_obj(df, datafile+'_classified')\n",
    "    print(' Done! {0}'.format(datetime.datetime.utcnow()))\n",
    "    return df\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309dda9",
   "metadata": {},
   "source": [
    "## 色やパラメーターの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5698f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot defaults for all plots\n",
    "mpl.rcParams.update({'font.size': 8})\n",
    "mpl.rcParams.update({'figure.dpi': 100})\n",
    "# Parameters for all plots:\n",
    "quasar_c = 'hotpink'\n",
    "star_c = 'dodgerblue'\n",
    "#galaxy_c = 'slategrey'\n",
    "galaxy_c = (101/255,236/255,101/255) # alexgreen\n",
    "# consistent colours for hexbin colourscale\n",
    "colors_g = [(1,1,1), (101/255,236/255,101/255)] # alexgreen\n",
    "cmap_g = make_cmap(colors_g)\n",
    "colors_q = [(1,1,1), (255/255,105/255,180/255)]\n",
    "cmap_q = make_cmap(colors_q)\n",
    "colors_s = [(1,1,1), (30/255,144/255,255/255)]\n",
    "cmap_s = make_cmap(colors_s)\n",
    "\n",
    "ls = '-'\n",
    "linewidth = 1\n",
    "rotation = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe53495",
   "metadata": {},
   "source": [
    "##  特徴別　：　未分類天体の分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  特徴量[psf , ishape, color] 等級制限あり\n",
    "\n",
    "psf = ['g_psfflux_mag','r_psfflux_mag', 'i_psfflux_mag', 'z_psfflux_mag', 'y_psfflux_mag']\n",
    "color = ['g-r', 'r-i', 'i-z', 'z-y']\n",
    "feature_columns = psf + ['ishape'] + color\n",
    "place = \"psf_ishape_color\" \n",
    "\n",
    "print('Loading data...')\n",
    "new_sources = [\"1_0_ra_20\", \"2_20_ra_30\", \"3_30_ra_40\",\"4_40_ra_60\",\"5_60_ra_120\",\"6_120_ra_140\",\"7_140_ra_160\",\"8_160_ra_180\",\"9_180_ra_200\",\"10_200_ra_210\",\"11_210_ra_220\",\"12_220_ra_240\",\"13_240_ra_300\",\"14_300_ra_330\",\"15_330_ra_360\"]\n",
    "\n",
    "for i, datafile_classified in enumerate(new_sources):\n",
    "    print('\\ncounting rows in {}.'.format(new_sources[i]))\n",
    "    df = load_obj('HSC_new_sources/{}'.format(datafile_classified))\n",
    "    if len(df) == 0:\n",
    "        print('There are {} rows'.format(len(df)))\n",
    "        continue\n",
    "    df = df[(df['g_psfflux_mag'] < 25) & (df['r_psfflux_mag'] < 25) & (df['i_psfflux_mag'] < 24.7) & (df['z_psfflux_mag'] < 23.7) & (df['y_psfflux_mag'] < 22.9)]\n",
    "    # ishapeの欠損値をなくす \n",
    "    df = df.dropna(subset=['ishape'])\n",
    "    print('There are {} rows'.format(len(df)))\n",
    "    df_classified = classify_new_sources(df, feature_columns, new_sources[i], place)\n",
    "    if i == 0:\n",
    "        df_all = df_classified\n",
    "    else:\n",
    "        df_all = pd.concat([df_all, df_classified], axis=0, ignore_index=True, sort=False)\n",
    "        \n",
    "save_obj(df_all, 'HSC_classifynew/'+place+'/mag_lim/classified_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  特徴量[psf , ishape, color] 等級制限なし\n",
    "\n",
    "# psf = ['g_psfflux_mag','r_psfflux_mag', 'i_psfflux_mag', 'z_psfflux_mag', 'y_psfflux_mag']\n",
    "# color = ['g-r', 'r-i', 'i-z', 'z-y']\n",
    "# feature_columns = psf + ['ishape'] + color\n",
    "# place = \"psf_ishape_color\"\n",
    "\n",
    "# print('Loading data...')\n",
    "# new_sources = [\"1_0_ra_20\", \"2_20_ra_30\", \"3_30_ra_40\",\"4_40_ra_60\",\"5_60_ra_120\",\"6_120_ra_140\",\"7_140_ra_160\",\"8_160_ra_180\",\"9_180_ra_200\",\"10_200_ra_210\",\"11_210_ra_220\",\"12_220_ra_240\",\"13_240_ra_300\",\"14_300_ra_330\",\"15_330_ra_360\"]\n",
    "\n",
    "# for i, datafile_classified in enumerate(new_sources):\n",
    "#     print('\\ncounting rows in {}.'.format(new_sources[i]))\n",
    "#     df = load_obj('HSC_new_sources/{}'.format(datafile_classified))\n",
    "#     if len(df) == 0:\n",
    "#         print('There are {} rows'.format(len(df)))\n",
    "#         continue\n",
    "#     # ishapeの欠損値をなくす \n",
    "#     df = df.dropna(subset=['ishape'])\n",
    "#     print('There are {} rows'.format(len(df)))\n",
    "#     df_classified = classify_new_sources(df, feature_columns, new_sources[i], place)\n",
    "#     if i == 0:\n",
    "#         df_all = df_classified\n",
    "#     else:\n",
    "#         df_all = pd.concat([df_all, df_classified], axis=0, ignore_index=True, sort=False)\n",
    "        \n",
    "# save_obj(df_all, 'HSC_classifynew/'+place+'/no_mag_lim/classified_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e803d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  特徴量[cmodel , ishape, color] 等級制限あり\n",
    "\n",
    "# cmodel = ['g_cmodel_mag', 'r_cmodel_mag', 'i_cmodel_mag', 'z_cmodel_mag', 'y_cmodel_mag']\n",
    "# color = ['g-r', 'r-i', 'i-z', 'z-y']\n",
    "# feature_columns = cmodel + ['ishape'] + color\n",
    "# feature_labels = ['g','r','i','z','y', '$\\mathrm{ishape}$', 'g-r', 'r-i', 'i-z', 'z-y']\n",
    "# place = 'cmodel_ishape_color\n",
    "\n",
    "# print('Loading data...')\n",
    "# new_sources = [\"1_0_ra_20\", \"2_20_ra_30\", \"3_30_ra_40\",\"4_40_ra_60\",\"5_60_ra_120\",\"6_120_ra_140\",\"7_140_ra_160\",\"8_160_ra_180\",\"9_180_ra_200\",\"10_200_ra_210\",\"11_210_ra_220\",\"12_220_ra_240\",\"13_240_ra_300\",\"14_300_ra_330\",\"15_330_ra_360\"]\n",
    "\n",
    "# for i, datafile_classified in enumerate(new_sources):\n",
    "#     print('\\ncounting rows in {}.'.format(new_sources[i]))\n",
    "#     df = load_obj('HSC_new_sources/{}'.format(datafile_classified))\n",
    "#     if len(df) == 0:\n",
    "#         print('There are {} rows'.format(len(df)))\n",
    "#         continue\n",
    "#     df = df[(df['g_psfflux_mag'] < 25) & (df['r_psfflux_mag'] < 25) & (df['i_psfflux_mag'] < 24.7) & (df['z_psfflux_mag'] < 23.7) & (df['y_psfflux_mag'] < 22.9)]\n",
    "#     # ishapeの欠損値をなくす \n",
    "#     df = df.dropna(subset=['ishape'])\n",
    "#     print('There are {} rows'.format(len(df)))\n",
    "#     df_classified = classify_new_sources(df, feature_columns, new_sources[i], place)\n",
    "#     if i == 0:\n",
    "#         df_all = df_classified\n",
    "#     else:\n",
    "#         df_all = pd.concat([df_all, df_classified], axis=0, ignore_index=True, sort=False)\n",
    "        \n",
    "# save_obj(df_all, 'HSC_classifynew/'+place+'/mag_lim/classified_source')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc90881",
   "metadata": {},
   "source": [
    "## 解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Separating classes into separate dfs...')\n",
    "df_g = df_all[df_all['class_pred']=='GALAXY']\n",
    "df_q = df_all[df_all['class_pred']=='QSO']\n",
    "df_s = df_all[df_all['class_pred']=='STAR']\n",
    "\n",
    "df_spec = load_spec(place)\n",
    "print_result_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_lim = True\n",
    "# ishape のビン\n",
    "bins_i = 10 ** np.linspace(np.log10(1), np.log10(10000), 100)\n",
    "\n",
    "print('Loading df with spec objects...')\n",
    "\n",
    "if mag_lim:\n",
    "    df_classified = load_obj('HSC_classifynew/' + place + '/mag_lim/classified_source')\n",
    "else:\n",
    "    df_classified = load_obj('HSC_classifynew/' + place + '/no_mag_lim/classified_source')\n",
    "    \n",
    "plot_basic_hists(df_classified, df_spec, place)\n",
    "plot_new_feature_hist(df_spec, df_g, df_q, df_s, place)\n",
    "plot_new_prob_hist(df_spec, df_g, df_q, df_s, place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11883721",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Newly classified sources: ')\n",
    "print(df_classified['class_pred'].value_counts())\n",
    "print(' Galaxies with prob greater than 0.9 and 0.99: {0}, {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_classified[df_classified['prob_g'] > 0.9]), len(df_classified[df_classified['prob_g'] > 0.99]), len(df_classified[df_classified['prob_g'] > 0.9])/len(df_g), len(df_classified[df_classified['prob_g'] > 0.99])/len(df_g) ) )\n",
    "print(' Quasars with prob greater than 0.9 and 0.99: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_classified[df_classified['prob_q'] > 0.9]), len(df_classified[df_classified['prob_q'] > 0.99]), len(df_classified[df_classified['prob_q'] > 0.9])/len(df_q), len(df_classified[df_classified['prob_q'] > 0.99])/len(df_q) ) )\n",
    "print(' Stars with prob greater than 0.9 and 0.99: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_classified[df_classified['prob_s'] > 0.9]), len(df_classified[df_classified['prob_s'] > 0.99]), len(df_classified[df_classified['prob_s'] > 0.9])/len(df_s), len(df_classified[df_classified['prob_s'] > 0.99])/len(df_s) ) )\n",
    "\n",
    "print(df_classified['class_pred'].value_counts())\n",
    "print(' Galaxies with prob greater than 0.7 and 0.8: {0}, {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_classified[df_classified['prob_g'] > 0.7]), len(df_classified[df_classified['prob_g'] > 0.8]), len(df_classified[df_classified['prob_g'] > 0.7])/len(df_g), len(df_classified[df_classified['prob_g'] > 0.8])/len(df_g) ) )\n",
    "print(' Quasars with prob greater than 0.7 and 0.8: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_classified[df_classified['prob_q'] > 0.7]), len(df_classified[df_classified['prob_q'] > 0.8]), len(df_classified[df_classified['prob_q'] > 0.7])/len(df_q), len(df_classified[df_classified['prob_q'] > 0.8])/len(df_q) ) )\n",
    "print(' Stars with prob greater than 0.7 and 0.8: {0} {1} : as fraction of total: {2:.2f} {3:.2f}'.format( len(df_classified[df_classified['prob_s'] > 0.7]), len(df_classified[df_classified['prob_s'] > 0.8]), len(df_classified[df_classified['prob_s'] > 0.7])/len(df_s), len(df_classified[df_classified['prob_s'] > 0.8])/len(df_s) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4b95d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
